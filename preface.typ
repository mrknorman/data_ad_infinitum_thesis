#set page(numbering: "i", number-align: center)
#counter(page).update(1)
#set heading(numbering: "I.a")

// Summary
= Summary

This thesis investigates the application of machine learning to gravitational-wave data analysis. Primarily, it focuses on artificial neural networks, but it also presents work to optimize the design and application of these networks with genetic algorithms, another machine learning method. This method of hyperparameter optimisation was utilised to design models for a low-latency burst search pipeline, MLy. Along with the use of genetic algorithms for hyperparameter optimisation, work is also performed to test the performance of attention-based networks on two gravitational wave data analysis tasks, compact binary coalescence detection, and estimating parameters of overlapping pairs of compact binary coalescences.

@gravitational-waves-sec introduces gravitational wave science, in order to contextualize the data analysis problems examined throughout. 

@machine-learning-sec examines the underlying principles of artificial neural networks and demonstrates a simple toy example to demonstrate the effectiveness of neural networks as a data analysis method. 

@application-sec then explores the intersection between the two introduced fields. It presents the methodology used for training dataset generation throughout the thesis, introducing the custom software developed in order to enable rapid dataset generation and iteration. It also contains a review of previous work that has been done to use artificial neural networks for gravitation wave data analysis, as well as a series of experiments to demonstrate the ineffectiveness of unspecialized artificial neural networks for the task. This section concludes with recreations of some important results from the literature which act as a comparative baseline for the rest of the thesis.

@dragonn-sec presents Dragonn, a genetic algorithm that can act as a general optimisation method for neural networks in gravitational wave data science, capable of optimising the network, the training dataset, and the training procedure simultaneously, and allowing for the easy addition of new hyperparameters.

@skywarp-sec presents experiments to test the effectiveness of attention-based networks for gravitational-wave analysis, more specifically, compact binary coalescence detection. It demonstrates a marginal improvement over the recreated convolutional neural networks from the literature, presented in @application-sec. 

Finally, @crosswave-sec expands the exploration of attention-based models to investigate cross-attention between multiple gravitational-wave detector outputs. We use this novel approach to examine the problem of parameter estimation on overlapping signals. 

#pagebreak()

// Table of contents.
#show outline: set heading(numbering: "I.a")
#outline(depth: 3, indent: true)
#pagebreak()

// Figures

= List of Figures

#locate(loc => {
  let elems = query(figure, loc)
    
  let count = 1
  for fig in elems {
    if fig.supplement.text == "Figure" {
      let supp = fig.supplement 
      let body = fig.caption.body
      let label = link(fig.label, strong(supp + " " + str(count)))
      label + " | " + body + "\n"

      count += 1
    }

  }
  
})

#pagebreak()

// Tables
= List of Tables

#locate(loc => {
  let elems = query(figure, loc)
    
  let count = 1
  for fig in elems {
    if fig.supplement.text == "Table" {
      let supp = fig.supplement 
      let body = fig.caption.body
      let label = link(fig.label, strong(supp + " " + str(count)))
      label + " | " + body + "\n"

      count += 1
    }

  }
  
})
 
#pagebreak()

// Collaborative Work
= Collaborative Work

A small amount of the work presented in this thesis was perfomed in collaboration with others. Here is a list of the sections that contain some collaborative work:

- Several of the figures used in @gravitational-waves-sec were produced by Meryl Kinnear using her impressive knowledge of Mathematica. Specifically, these were: @flat, @gravitaional-potentials, and @waves which is also the image on the half-cover page. This was done as a favour to me and is greatly appreciated.
- Although the work done to train the MLy models using the genetic algorithm-based hyperparameter optimisation method presented in this these was not strictly collaborative, it is described in @deployment-in-mly as an example use case of the method. Work to optimise and train these models was performed solely by Vasileios Skliris, with whom I have collaborated in the past on development work for the MLy pipeline, but not for any of the work presented in this thesis other than what is mentioned in @deployment-in-mly.
- The work presented in @crosswave-sec was collaborative. The problem was presented, and the training and testing datasets were generated by Philip J. Relton. I performed all the work to create and train the models, although some guidance on the nature of the problem and the importance of different aspects was provided by Phil. Our collaboration extended only to the first of the models presented, Overlapnet, after which Phil left the project. The parameter estimation model, CrossWave, was a continuation of the concept, and the same training and validation datasets generated by Phil were used, however, there was no further input from Phil in the training of CrossWave. All data analysis was performed independently, although again, the importance of certain aspects of the problem had previously been highlighted by Phil.

#pagebreak()

// Acknowledgments
= Acknowledgments

A great number of people, fortuitous events, and cups of coffee were required to create the conditions necessary for the production of this thesis. It would be a hopeless task to try and name them all --- perhaps I could train a neural network to do it though? Nonetheless, I will attempt to highlight and express my overwhelming gratitude toward the most crucial contributors. 

Firstly, I would like to thank my supervisor Patrick Sutton. He has helped improve my skills as a scientist in innumerable ways and managed to direct me toward my goal whilst still providing me with the freedom to explore my own ideas. I imagine achieving this balance must be one of the most difficult parts of being a Ph.D. supervisor, but he has managed to excel at the task.

Of course, I need to cover the basics, although thankfully in this case it is not down to a sense of obligation. I have the most supportive family anyone could ever wish for. I am fortunate enough that they have never been a single moment of doubt, a single question as to whether this is a thing I could do, and whether it is a thing I should do. They have always been there, in the background, to support me and let me know that even if things didn't work out, it would be okay in the end. I give special thanks to my father, Mark, who has always shown an interest in my work and even attempted to read this thesis, and my mother Caroline, who sends me an advent calendar every year.

Speaking of support, I would be remiss not to mention my source of funding, AIMLAC, (it's a terrible acronym, I won't do it the dignity of expanding it), and the wonderful people who run it. I have made many hopefully enduring connections through the myriad of conferences and events they put on for us, both academically and socially. Through AIMLAC, I have met many people whom I now consider friends, including Tom, Hattie, Ben, Cory, Maciek, Sophie, Robbie, and Tonichia.

Perhaps the largest contribution to the ideas behind this project, and the intersection between gravitational waves and machine learning research at Cardiff, comes from 
Vasileios Skliris. He was Patrick's student prior to me and paved much of the path that this work follows. Despite having to deal with me and my constant stream of new ideas, he continues to push for real applications of machine learning methods with his development of the MLy pipeline.

Next, we come to those who have supported me beyond an academic sense, but whose roles have been of equal importance. Without them, the thought of four years of Ph.D. work is almost incomprehensible (although maybe I could have got it done in two if I didn't have anyone in the office that I could distract). There are a great many people who fit into this category and I will certainly forget some of them (plus the thesis is long enough as it is). Firstly, Phil, Zoltan, and Sander, you kept me sane with many opportunities for terrible coffees, shots of gin, and opportunities to rant about A.I. destroying the world. I already miss you all. I'd also be remiss not to mention all those who came before me, including Ali, Johnathan, and Virginia, who are hopefully enjoying the sunshine in California; and all those who will remain here after I'm gone (I swear I'm perfectly healthy), including Abhinav, Debatri, Jordan, Wasim, and of course Sama, who promised to read my thesis when it's done (I'm sorry it's so long. Good luck). I hope that she will continue to work on our join unstarted project, Crocodile. I will also mention friends I have somehow managed to retain from outside gravitational waves, all of whom are very dear to me: Harvey, Luke, Patrick, and Elliot. With special thanks to Elliot, who has been my agony aunt through many situations. Oh, and probably some astronomers too.

Lastly, (I put these three in a separate paragraph because I think it'll be funny if they think I've missed them) thank you to Meryl, Terri, and Eva. Thank you for encouraging me to write an acknowledgments section, for supplying me with a good proportion of my current wardrobe, and for your unsuccessful attempts to help me get over my fear of sauce. You've made this last year a lot less stressful than it could have been.